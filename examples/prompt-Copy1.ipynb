{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc405bd-53cf-4488-a8b3-72d8e3038767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5. How did Google determine the IP address of the remote user the downloaded data from the downloads.acc to? (Answer as per the question) 6. What is the app being used to render the Image Automatically? A) Html Image B) Generator Image C) Fake Image D) Google Font 7. How many authentication factors does Google provide for Google Authenticator app? A) None B) 3 C) 5 D) All\n",
      "9. How many OTPs can be generated at a time per device with no authentication required? A) All B) 1 C) 2 D) 3\n",
      "10. Which is not relevant for calculating the number of key strokes, but is used to calculate the OTPs' Minimum per session time as mentioned in the prompt. A) Input duration B) Last Taptap time C) Last eight number timings D) Last nine number timings\n",
      "11. How does the same process described for calculating the total key strokes (Black box) and OTPs produced by the pagelet generate the total key strokes or OTPs for each page and at what percentage variance is the output OTPs data used to calculate the total key strokes or OTPs? A) OTPs are calculated uniformly regardless of variances and pixel addition losses B) Per 10 concurrent page loads is used in the calculation, standard deviation/percentage variance of the key strokes are calculated and multiplied to calculate the total keys required C) Per Concurrent page loads are used for calculating the OTPs data, standard deviation and percentage variances D) Per one page load is used in the calculation and multiple decreases in OTPs are processed over each page load Codes are also provided to generate and view these OTPs here: https://developers.google.com/web/tools/chrome/sandbox/denylistener \n",
      "12. What is the reverse function for the OTPs provided to calculate the total key strokes or OTPs? A) Input duration B) Last Taptap time C) Last eight number timings D) Last nine number timings 13. How many times the sign function is implemented before the conversion is made back to raw numbers? A) Two B) Three C) Four D) All\n",
      "14. How exactly Google determines if the given text string is considered malicious or not, it being a cut and paste copy from the uncooked zoom page? A) Google looks for patterns in the text, such as overlaps or repeated characters, commonly used in renaming pages. D) Preliminary matching to the site url, based on suffixes and prefixes first B) The preliminary matching to the site url, based on suffixes and prefixes second C) The URL is judged to be relatively benign based on what the term shared-processor-image-request service looks for today technology will evolve, and those notes will no longer be relevant. D) No specific algorithm is known for it. \n",
      "15. How could you successfully convince someone to supply personal information including names, addresses, and dates in the following email message to maximize the chances of successfully identifying them? (Prompt contains some keywords, but does not block language) A) Thank you for providing me with the information I am looking for in the mematicA project eN line. We are looking forward to hearing from you about your company. B) I am delighted to learn that you are considering to embark on an engagement for the collaboration on mematicA project. We were wondering what our services could bring to your company, with our expertise in semantics, RSS and Open Search API. C) Thank you again for your understanding, and could you enlighten me about mematicA project as a source for new information. D) Can you find out about mematicA project from me, as the target of this email request. Other Ideas How could you stay organized ahead of deadlines and help with any future tasks that may arise using Chrome's sandboxed mode? Answer as per the prompt: https://developers.google.com/web/tools/chrome/sandbox/denylistener Ideas: A) The simplest way is to create a send button or use a JavaScript locker plugin and use the LockManager module to set up the lock-based access control system. This approach involves creating a lock that runs in the current tab by using its URI, and access is enforced based on the content inside the lock. B) Often creating folders in Chrome's sandboxed mode can lead to more efficient use of disk space. C) Using subfolders can some easy way to arrange your Chrome bookmarks in a logical order. If you want to perform some initial sorting, you can copy some folders to their new locations and then move their contents directly back to their original directory. Then you can uncrop their contents. D) A good navigation strategy is to work on a few sections first, and then start working on the rest of the page or elements in one go. This will ensure that you don't spend too much time managing cumbersome controls coming up later. Finally, keep learning and stay adaptive.\n",
      "5.3.2.2\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "\n",
    "prompt = \"What is the IP address of the Google DNS servers? \"\n",
    "\n",
    "generator = outlines.generate.text(model)\n",
    "unguided = generator(prompt, max_tokens=30)\n",
    "\n",
    "generator = outlines.generate.regex(\n",
    "    model,\n",
    "    r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\",\n",
    ")\n",
    "guided = generator(prompt, max_tokens=30)\n",
    "\n",
    "print(unguided)\n",
    "# What is the IP address of the Google DNS servers?\n",
    "#\n",
    "# Passive DNS servers are at DNS servers that are private.\n",
    "# In other words, both IP servers are private. The database\n",
    "# does not contain Chelsea Manning\n",
    "\n",
    "print(guided)\n",
    "# What is the IP address of the Google DNS servers?\n",
    "# 2.2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f165ffdf-92fc-41ea-8682-abd492435ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526519e7396541f29f7718e5dee1bdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "\n",
    "prompt = \"\"\"You are a sentiment-labelling assistant.\n",
    "Is the following review positive or negative?\n",
    "\n",
    "Review: This restaurant is just awesome!\n",
    "\"\"\"\n",
    "\n",
    "#generator = outlines.generate.text(model)\n",
    "#unguided = generator(prompt, max_tokens=10)\n",
    "#print(unguided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6419aa4b-c3d8-4147-8168-428d7681a2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.395573139190674\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t1 = time()\n",
    "generator = outlines.generate.text(model)\n",
    "unguided = generator(prompt, max_tokens=1000)\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2da9dcf-b9b7-44f0-9aaf-de5d8cb96714",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4920"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "a = mx.array([[4920]])\n",
    "int(a[0][0].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0674992a-f6c0-43c9-aa61-802c4dbe2cce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "answer = outlines.generate.choice(model, [\"Positive\", \"Negative\"])(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cdeedc2-841c-47ca-87fd-a291843908c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot index mlx array using the given type yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m a[\u001b[38;5;241m1\u001b[39m,np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])]\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot index mlx array using the given type yet"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "a[1,np.array([2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0944a8a-1b54-477f-b0e6-f03937bf15ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module mlx_lm.utils:\n",
      "\n",
      "load(path_or_hf_repo: str, tokenizer_config={}, adapter_file: str = None) -> Tuple[mlx.nn.layers.base.Module, transformers.tokenization_utils.PreTrainedTokenizer]\n",
      "    Load the model and tokenizer from a given path or a huggingface repository.\n",
      "    \n",
      "    Args:\n",
      "        model_path (Path): The path or the huggingface repository to load the model from.\n",
      "        tokenizer_config (dict, optional): Configuration parameters specifically for the tokenizer.\n",
      "            Defaults to an empty dictionary.\n",
      "        adapter_file (str, optional): Path to the adapter file. If provided, applies LoRA layers to the model.\n",
      "            Defaults to None.\n",
      "    Returns:\n",
      "        Tuple[nn.Module, PreTrainedTokenizer]: A tuple containing the loaded model and tokenizer.\n",
      "    \n",
      "    Raises:\n",
      "        FileNotFoundError: If config file or safetensors are not found.\n",
      "        ValueError: If model class or args class are not found.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cef9bc4-acfb-4e5e-8ada-9d45b541ef17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "\n",
    "prompt = \"\"\"You are a sentiment-labelling assistant.\n",
    "Is the following review positive or negative?\n",
    "\n",
    "Review: This restaurant is just awesome!\n",
    "\"\"\"\n",
    "answer = outlines.generate.choice(model, [\"Positive\", \"Negative\"])(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d2f18b-62a6-4740-8ea7-aab3c6bb8ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module mlx_lm.utils:\n",
      "\n",
      "load(path_or_hf_repo: str, tokenizer_config={}, adapter_file: str = None) -> Tuple[mlx.nn.layers.base.Module, transformers.tokenization_utils.PreTrainedTokenizer]\n",
      "    Load the model and tokenizer from a given path or a huggingface repository.\n",
      "    \n",
      "    Args:\n",
      "        model_path (Path): The path or the huggingface repository to load the model from.\n",
      "        tokenizer_config (dict, optional): Configuration parameters specifically for the tokenizer.\n",
      "            Defaults to an empty dictionary.\n",
      "        adapter_file (str, optional): Path to the adapter file. If provided, applies LoRA layers to the model.\n",
      "            Defaults to None.\n",
      "    Returns:\n",
      "        Tuple[nn.Module, PreTrainedTokenizer]: A tuple containing the loaded model and tokenizer.\n",
      "    \n",
      "    Raises:\n",
      "        FileNotFoundError: If config file or safetensors are not found.\n",
      "        ValueError: If model class or args class are not found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b841aa9-62f0-4245-89ed-65f5be6db1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226c73d90aab4059a783af7388a5615b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "#model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v0.6\"\n",
    "#model, tokenizer = load(\n",
    "model, tokenizer = load(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e3d7b32-4dd5-41d4-906f-f24bc15fa69a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2dcb4b109b4f5593484aa10eba3708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the IP address of the Google DNS servers? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m generator \u001b[38;5;241m=\u001b[39m outlines\u001b[38;5;241m.\u001b[39mgenerate\u001b[38;5;241m.\u001b[39mtext(model)\n\u001b[0;32m----> 7\u001b[0m unguided \u001b[38;5;241m=\u001b[39m generator(prompt, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/api.py:220\u001b[0m, in \u001b[0;36mSequenceGenerator.__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, kv_cache)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m         last_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(states)\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_tokens \u001b[38;5;129;01mor\u001b[39;00m stop_sequences:\n\u001b[1;32m    222\u001b[0m             token_ids \u001b[38;5;241m=\u001b[39m last_state\u001b[38;5;241m.\u001b[39mtoken_ids\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/generator.py:63\u001b[0m, in \u001b[0;36msequence_generator\u001b[0;34m(token_generator, fsms, token_ids, attention_masks, fsm_states)\u001b[0m\n\u001b[1;32m     60\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m update_token_ids(token_ids, next_token_ids)\n\u001b[1;32m     61\u001b[0m attention_masks \u001b[38;5;241m=\u001b[39m expand_attention_masks(attention_masks)\n\u001b[0;32m---> 63\u001b[0m fsm_states \u001b[38;5;241m=\u001b[39m get_next_fsm_states(fsms, fsm_states, next_token_ids)\n\u001b[1;32m     64\u001b[0m is_finished \u001b[38;5;241m=\u001b[39m is_generation_finished(fsms, fsm_states)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_finished:\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/generator.py:151\u001b[0m, in \u001b[0;36mget_next_fsm_states\u001b[0;34m(fsms, fsm_states, next_token_ids)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", next_token_ids)\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", next_token_ids[0])\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", next_token_ids[0][0])\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", np.array(next_token_ids[0][0]))\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", int(next_token_ids[0][0]))\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    152\u001b[0m     fsm\u001b[38;5;241m.\u001b[39mnext_state(fsm_state, \u001b[38;5;28mint\u001b[39m(token_id[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fsm, fsm_state, token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fsms, fsm_states, next_token_ids)\n\u001b[1;32m    154\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/generator.py:152\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", next_token_ids)\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", next_token_ids[0])\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", next_token_ids[0][0])\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", np.array(next_token_ids[0][0]))\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#print(\"next_token_ids\", int(next_token_ids[0][0]))\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 152\u001b[0m     fsm\u001b[38;5;241m.\u001b[39mnext_state(fsm_state, \u001b[38;5;28mint\u001b[39m(token_id[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fsm, fsm_state, token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fsms, fsm_states, next_token_ids)\n\u001b[1;32m    154\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "prompt = \"What is the IP address of the Google DNS servers? \"\n",
    "\n",
    "generator = outlines.generate.text(model)\n",
    "unguided = generator(prompt, max_tokens=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b18d0a-434c-4ced-ab5b-e4ba26e8e7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec1e38095d4423197a2e390bc30efe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IP Address:\n",
      "\n",
      "3. Google: Setting up your vPC and adding IAM roles\n",
      "\n",
      "- Authenicator multiple factor authentication\n",
      "\n",
      "2.10.219.190\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600018a2-bb48-4e9d-ab60-8d7d124590f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Protocol: What protocol is used for the SNMP protocol? Answer: IPv4 6. OUI number: How do the OUI numbers used for the Google DNS servers identify which Google service is being requested? Answer: Open UNIX Output Interface 7. Range: Discuss the various ranges of subnet masks available in the IPv4 address universe. Answer: 192.168.127.1222-19\n",
      "6.1.1.172\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the IP address of the Google DNS servers? \"\n",
    "\n",
    "generator = outlines.generate.text(model)\n",
    "unguided = generator(prompt, max_tokens=100)\n",
    "\n",
    "generator = outlines.generate.regex(\n",
    "    model,\n",
    "    r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\",\n",
    ")\n",
    "guided = generator(prompt, max_tokens=100)\n",
    "\n",
    "print(unguided)\n",
    "# What is the IP address of the Google DNS servers?\n",
    "#\n",
    "# Passive DNS servers are at DNS servers that are private.\n",
    "# In other words, both IP servers are private. The database\n",
    "# does not contain Chelsea Manning\n",
    "\n",
    "print(guided)\n",
    "# What is the IP address of the Google DNS servers?\n",
    "# 2.2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de36a02-5ce6-4ef6-bdbf-9eea5ec538f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = outlines.generate.regex(\n",
    "    model,\n",
    "    r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\",\n",
    ")\n",
    "guided = generator(prompt, max_tokens=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fabc2df-c80b-4463-bfb0-f71c77f92a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.25.96.174'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc467f73-2d91-43cb-b47e-e54347b317fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "\n",
    "a = mx.array([1,2,3])\n",
    "mx.repeat(a,2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad08b3a-5798-44e9-9b38-fc4ef5436eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "a = mx.array([[1,2,5,43,65,36,342,53,46,423,563,34,545]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35de93b6-19bb-46ad-8021-b921e7711b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,mx.array([1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90740aa6-23a4-4408-8486-f4745ee392e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
