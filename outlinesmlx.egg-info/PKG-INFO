Metadata-Version: 2.1
Name: outlinesmlx
Version: 0.0.27
Summary: Probabilistic Generative Model Programming
Author: Sacha Ichbiah
Project-URL: repository, https://github.com/sacha-ichbiah/outlines-mlx/
Keywords: machine learning,deep learning,language models,guided generation
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: interegular
Requires-Dist: jinja2
Requires-Dist: lark
Requires-Dist: nest_asyncio
Requires-Dist: numpy
Requires-Dist: perscache
Requires-Dist: pydantic>=2.0
Requires-Dist: scipy
Requires-Dist: torch>=2.1
Requires-Dist: numba
Requires-Dist: joblib
Requires-Dist: referencing
Requires-Dist: jsonschema
Requires-Dist: requests
Requires-Dist: ai2-olmo
Requires-Dist: mlx_lm
Requires-Dist: outlines==0.0.27
Provides-Extra: test
Requires-Dist: pre-commit; extra == "test"
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-cov; extra == "test"
Requires-Dist: transformers; extra == "test"
Requires-Dist: coverage[toml]>=5.1; extra == "test"
Requires-Dist: diff-cover; extra == "test"
Requires-Dist: accelerate; extra == "test"
Requires-Dist: beartype<0.16.0; extra == "test"
Requires-Dist: datasets; extra == "test"
Requires-Dist: responses; extra == "test"



# Outlines-mlx
    
Outlines MLX is a minimalistic library aims at adapting the Outlines library within the MLX framework.
[Outlines](https://github.com/outlines-dev/outlines/) provides ways to control the generation of language models to make their output more predictable.
Combined with [MLX](https://github.com/ml-explore/mlx), it allows to perform guided-generation with large language models while leveraging Apple Silicon hardware. 

<img src="logo.png" alt="Outlines-MLX" width=300></img>

## Design principles

We design it as an adapter that replaces the Pytorch parts of the original Outlines library, to replace it with MLX compatible parts.

We will continue to update it actively as Outlines evolves with time. 

## Why Outlines MLX ?

We are convinced that guided generation is an important technology that will define the future of AI applications beyond chatbots. As the Apple Silicon ML accelerators  become increasingly powerful, we want to extend guided-generation capabilities to this family of devices.

## Installation
``` bash
git clone sacha-ichbiah/outlines-mlx
cd outlines-mlx
pip install -e . 
```


## Features

Check the original repository to see the available features.


## Supported models

The supported models are:

| Models                             | 
|------------------------------------|
| TinyLlama/TinyLlama-1.1B-Chat-v0.6 |
| microsoft/phi-2                    |
| mistralai/Mistral-7B               |



### Load model with a MLX backend

Check the original [Outlines](https://github.com/outlines-dev/outlines/) library for more use cases.

``` python
import outlinesmlx as outlines

model = outlines.models.mlx("TinyLlama/TinyLlama-1.1B-Chat-v0.6")

prompt = """You are a sentiment-labelling assistant.
Is the following review positive or negative?

Review: This restaurant is just awesome!
"""
answer = outlines.generate.choice(model, ["Positive", "Negative"])(prompt)
```



### Model quantization

Run large models on hardware with strong limitations with 4-Bit quantization.

``` python
import outlinesmlx as outlines

#model = outlines.models.mlx("microsoft/phi-2",model_kwargs={'trust_remote_code':True, 'quantize':True, 'q_group_size':64,"q_bits":4, "force_conversion":True}, tokenizer_kwargs= {'trust_remote_code':True})
model = outlines.models.mlx("mistralai/Mistral-7B-Instruct-v0.2",model_kwargs={'trust_remote_code':True, 'quantize':True, 'q_group_size':64,"q_bits":4, "test_loading_instruct":True,"force_conversion":True},tokenizer_kwargs= {'trust_remote_code':True})

prompt = "What is the IP address of the Google DNS servers? "

guided = outlines.generate.regex(model, r"((25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(25[0-5]|2[0-4]\d|[01]?\d\d?)", max_tokens=30)(prompt)

print(guided)
# What is the IP address of the Google DNS servers?
# 2.2.6.1
```

### Disclaimer

This library is not up to date. It was designed to perform experiments with guided generation on Apple Silicon M1/M2. Please check the original [Outlines](https://github.com/outlines-dev/outlines/) library for an up-to-date implementation. 

### Citation

Do not forget to cite the original paper !

``` bash
@article{willard2023efficient,
  title={Efficient Guided Generation for LLMs},
  author={Willard, Brandon T and Louf, R{\'e}mi},
  journal={arXiv preprint arXiv:2307.09702},
  year={2023}
}
```
